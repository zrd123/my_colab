{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "B3-63tsyIooG"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN4m1yPKVXeUXnBNtbIaBlD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zrd123/my_colab/blob/master/code/morden_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AlexNet"
      ],
      "metadata": {
        "id": "WkVUqcMq10EW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMHbyfe8tNs-"
      },
      "outputs": [],
      "source": [
        "!pip install d2l==0.17.6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "\n",
        "net = nn.Sequential(\n",
        "    # 这里使用一个11*11的更大窗口来捕捉对象。\n",
        "    # 同时，步幅为4，以减少输出的高度和宽度。\n",
        "    # 另外，输出通道的数目远大于LeNet\n",
        "    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
        "    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "    # 使用三个连续的卷积层和较小的卷积窗口。\n",
        "    # 除了最后的卷积层，输出通道的数量进一步增加。\n",
        "    # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度\n",
        "    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
        "    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
        "    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "    nn.Flatten(),\n",
        "    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合\n",
        "    nn.Linear(6400, 4096), nn.ReLU(),\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(4096, 4096), nn.ReLU(),\n",
        "    nn.Dropout(p=0.5),\n",
        "    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
        "    nn.Linear(4096, 10))"
      ],
      "metadata": {
        "id": "uN3oCdAatxzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.randn(1, 1, 224, 224)\n",
        "for layer in net:\n",
        "    X=layer(X)\n",
        "    print(layer.__class__.__name__,'output shape:\\t',X.shape)"
      ],
      "metadata": {
        "id": "fTYWRLCEtxux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)"
      ],
      "metadata": {
        "id": "ZBXl_BDltxrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr, num_epochs = 0.01, 10\n",
        "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
      ],
      "metadata": {
        "id": "tNjKv9b7txnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG"
      ],
      "metadata": {
        "id": "7NcjF4NMZgBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "\n",
        "\n",
        "def vgg_block(num_convs, in_channels, out_channels):\n",
        "    layers = []\n",
        "    for _ in range(num_convs):\n",
        "        layers.append(nn.Conv2d(in_channels, out_channels,\n",
        "                                kernel_size=3, padding=1))\n",
        "        layers.append(nn.ReLU())\n",
        "        in_channels = out_channels\n",
        "    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "yvf5zVlVtxiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))"
      ],
      "metadata": {
        "id": "vwUyns2QallO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vgg(conv_arch):\n",
        "    conv_blks = []\n",
        "    in_channels = 1\n",
        "    # 卷积层部分\n",
        "    for (num_convs, out_channels) in conv_arch:\n",
        "        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))\n",
        "        in_channels = out_channels\n",
        "\n",
        "    return nn.Sequential(\n",
        "        *conv_blks, nn.Flatten(),\n",
        "        # 全连接层部分\n",
        "        nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
        "        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
        "        nn.Linear(4096, 10))\n",
        "\n",
        "net = vgg(conv_arch)"
      ],
      "metadata": {
        "id": "QVNvntrKalik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.randn(size=(1, 1, 224, 224))\n",
        "for blk in net:\n",
        "    X = blk(X)\n",
        "    print(blk.__class__.__name__,'output shape:\\t',X.shape)"
      ],
      "metadata": {
        "id": "JQmxrp-balf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratio = 4\n",
        "small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]\n",
        "net = vgg(small_conv_arch)"
      ],
      "metadata": {
        "id": "axrfdCw0aldP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr, num_epochs, batch_size = 0.03, 10, 64\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
        "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
      ],
      "metadata": {
        "id": "kFjiBSNkauKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NiN"
      ],
      "metadata": {
        "id": "wiCIrBPBjLvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install d2l==0.17.6"
      ],
      "metadata": {
        "id": "6-n49OzZWyHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "\n",
        "\n",
        "def nin_block(in_channels, out_channels, kernel_size, strides, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU())"
      ],
      "metadata": {
        "id": "ceWeIMk1auHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(\n",
        "    nin_block(1, 96, kernel_size=11, strides=4, padding=0),\n",
        "    nn.MaxPool2d(3, stride=2),\n",
        "    nin_block(96, 256, kernel_size=5, strides=1, padding=2),\n",
        "    nn.MaxPool2d(3, stride=2),\n",
        "    nin_block(256, 384, kernel_size=3, strides=1, padding=1),\n",
        "    nn.MaxPool2d(3, stride=2),\n",
        "    nn.Dropout(0.5),\n",
        "    # 标签类别数是10\n",
        "    nin_block(384, 10, kernel_size=3, strides=1, padding=1),\n",
        "    nn.AdaptiveAvgPool2d((1, 1)),\n",
        "    # 将四维的输出转成二维的输出，其形状为(批量大小,10)\n",
        "    nn.Flatten())"
      ],
      "metadata": {
        "id": "QQ1ph9EcjWm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(size=(1, 1, 224, 224))\n",
        "for layer in net:\n",
        "    X = layer(X)\n",
        "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
      ],
      "metadata": {
        "id": "DO1E19ENjWir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr, num_epochs, batch_size = 0.12, 10, 128\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
        "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
      ],
      "metadata": {
        "id": "eLvqVgE4jWc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GoogLeNet"
      ],
      "metadata": {
        "id": "BwFl5DtXVJ6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from d2l import torch as d2l\n",
        "\n",
        "\n",
        "class Inception(nn.Module):\n",
        "    # c1--c4是每条路径的输出通道数\n",
        "    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):\n",
        "        super(Inception, self).__init__(**kwargs)\n",
        "        # 线路1，单1x1卷积层\n",
        "        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
        "        # 线路2，1x1卷积层后接3x3卷积层\n",
        "        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
        "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
        "        # 线路3，1x1卷积层后接5x5卷积层\n",
        "        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)\n",
        "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
        "        # 线路4，3x3最大汇聚层后接1x1卷积层\n",
        "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        p1 = F.relu(self.p1_1(x))\n",
        "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
        "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
        "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
        "        # 在通道维度上连结输出\n",
        "        return torch.cat((p1, p2, p3, p4), dim=1)"
      ],
      "metadata": {
        "id": "bwu8kJKmjWak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
        "                   nn.ReLU(),\n",
        "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "metadata": {
        "id": "NfJOKcofVOzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
        "                   nn.ReLU(),\n",
        "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "                   nn.ReLU(),\n",
        "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "metadata": {
        "id": "VdW1HXj5VOiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n",
        "                   Inception(256, 128, (128, 192), (32, 96), 64),\n",
        "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "metadata": {
        "id": "e4ek7mSSVOep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n",
        "                   Inception(512, 160, (112, 224), (24, 64), 64),\n",
        "                   Inception(512, 128, (128, 256), (24, 64), 64),\n",
        "                   Inception(512, 112, (144, 288), (32, 64), 64),\n",
        "                   Inception(528, 256, (160, 320), (32, 128), 128),\n",
        "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "metadata": {
        "id": "zxpB3mpsVOa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n",
        "                   Inception(832, 384, (192, 384), (48, 128), 128),\n",
        "                   nn.AdaptiveAvgPool2d((1,1)),\n",
        "                   nn.Flatten())\n",
        "\n",
        "net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 10))"
      ],
      "metadata": {
        "id": "4eubVtaCVOW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(size=(1, 1, 96, 96))\n",
        "for layer in net:\n",
        "    X = layer(X)\n",
        "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
      ],
      "metadata": {
        "id": "K4-QU-9RWmiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr, num_epochs, batch_size = 0.1, 10, 128\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
        "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
      ],
      "metadata": {
        "id": "e7D_8YjtWnV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 批量归一化"
      ],
      "metadata": {
        "id": "B3-63tsyIooG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 从零实现"
      ],
      "metadata": {
        "id": "6GyrH615huXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install d2l==0.17.6"
      ],
      "metadata": {
        "id": "CSqhb8w3kh-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "\n",
        "\n",
        "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
        "    # 通过is_grad_enabled来判断当前模式是训练模式还是预测模式\n",
        "    if not torch.is_grad_enabled():\n",
        "        # 如果是在预测模式下，直接使用传入的移动平均所得的均值和方差\n",
        "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
        "    else:\n",
        "        assert len(X.shape) in (2, 4)\n",
        "        if len(X.shape) == 2:\n",
        "            # 使用全连接层的情况，计算特征维上的均值和方差\n",
        "            mean = X.mean(dim=0)\n",
        "            var = ((X - mean) ** 2).mean(dim=0)\n",
        "        else:\n",
        "            # 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差。\n",
        "            # 这里我们需要保持X的形状以便后面可以做广播运算\n",
        "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
        "            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
        "        # 训练模式下，用当前的均值和方差做标准化\n",
        "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
        "        # 更新移动平均的均值和方差\n",
        "        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean\n",
        "        moving_var = momentum * moving_var + (1.0 - momentum) * var\n",
        "    Y = gamma * X_hat + beta  # 缩放和移位\n",
        "    return Y, moving_mean.data, moving_var.data"
      ],
      "metadata": {
        "id": "OEMT_kMgIstw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchNorm(nn.Module):\n",
        "    # num_features：完全连接层的输出数量或卷积层的输出通道数。\n",
        "    # num_dims：2表示完全连接层，4表示卷积层\n",
        "    def __init__(self, num_features, num_dims):\n",
        "        super().__init__()\n",
        "        if num_dims == 2:\n",
        "            shape = (1, num_features)\n",
        "        else:\n",
        "            shape = (1, num_features, 1, 1)\n",
        "        # 参与求梯度和迭代的拉伸和偏移参数，分别初始化成1和0\n",
        "        self.gamma = nn.Parameter(torch.ones(shape))\n",
        "        self.beta = nn.Parameter(torch.zeros(shape))\n",
        "        # 非模型参数的变量初始化为0和1\n",
        "        self.moving_mean = torch.zeros(shape)\n",
        "        self.moving_var = torch.ones(shape)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # 如果X不在内存上，将moving_mean和moving_var\n",
        "        # 复制到X所在显存上\n",
        "        if self.moving_mean.device != X.device:\n",
        "            self.moving_mean = self.moving_mean.to(X.device)\n",
        "            self.moving_var = self.moving_var.to(X.device)\n",
        "        # 保存更新过的moving_mean和moving_var\n",
        "        Y, self.moving_mean, self.moving_var = batch_norm(\n",
        "            X, self.gamma, self.beta, self.moving_mean,\n",
        "            self.moving_var, eps=1e-5, momentum=0.9)\n",
        "        return Y"
      ],
      "metadata": {
        "id": "rHjsHyQaItgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(\n",
        "    nn.Conv2d(1, 6, kernel_size=5), BatchNorm(6, num_dims=4), nn.Sigmoid(),\n",
        "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "    nn.Conv2d(6, 16, kernel_size=5), BatchNorm(16, num_dims=4), nn.Sigmoid(),\n",
        "    nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),\n",
        "    nn.Linear(16*4*4, 120), BatchNorm(120, num_dims=2), nn.Sigmoid(),\n",
        "    nn.Linear(120, 84), BatchNorm(84, num_dims=2), nn.Sigmoid(),\n",
        "    nn.Linear(84, 10))"
      ],
      "metadata": {
        "id": "dBNPpCs4h8e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr, num_epochs, batch_size = 1.0, 10, 96=\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
        "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
      ],
      "metadata": {
        "id": "mmQD7NNQh8Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net[1].gamma.reshape((-1,)), net[1].beta.reshape((-1,))"
      ],
      "metadata": {
        "id": "eOsZNufkh8Xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 简单实现"
      ],
      "metadata": {
        "id": "gZPZL6FVh8CX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(\n",
        "    nn.Conv2d(1, 6, kernel_size=5), nn.BatchNorm2d(6), nn.Sigmoid(),\n",
        "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "    nn.Conv2d(6, 16, kernel_size=5), nn.BatchNorm2d(16), nn.Sigmoid(),\n",
        "    nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),\n",
        "    nn.Linear(256, 120), nn.BatchNorm1d(120), nn.Sigmoid(),\n",
        "    nn.Linear(120, 84), nn.BatchNorm1d(84), nn.Sigmoid(),\n",
        "    nn.Linear(84, 10))"
      ],
      "metadata": {
        "id": "H-1GSDGBh8UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
      ],
      "metadata": {
        "id": "DjQGRVb2iNJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 残差神经网络"
      ],
      "metadata": {
        "id": "Tft3QLHuFEac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install d2l==0.17.6"
      ],
      "metadata": {
        "id": "VEdzilKKFbxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from d2l import torch as d2l\n",
        "\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, input_channels, num_channels,\n",
        "                 use_1x1conv=False, strides=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
        "                               kernel_size=3, padding=1, stride=strides)\n",
        "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
        "                               kernel_size=3, padding=1)\n",
        "        if use_1x1conv:\n",
        "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
        "                                   kernel_size=1, stride=strides)\n",
        "        else:\n",
        "            self.conv3 = None\n",
        "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "        if self.conv3:\n",
        "            X = self.conv3(X)\n",
        "        Y += X\n",
        "        return F.relu(Y)"
      ],
      "metadata": {
        "id": "cqgBB97kh8RX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blk = Residual(3,3)\n",
        "X = torch.rand(4, 3, 6, 6)\n",
        "Y = blk(X)\n",
        "Y.shape"
      ],
      "metadata": {
        "id": "jPdhyN56h8OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blk = Residual(3,6, use_1x1conv=True, strides=2)\n",
        "blk(X).shape"
      ],
      "metadata": {
        "id": "CFXT_IMlFN5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
        "                   nn.BatchNorm2d(64), nn.ReLU(),\n",
        "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "metadata": {
        "id": "94RWdhr-FNz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_block(input_channels, num_channels, num_residuals,\n",
        "                 first_block=False):\n",
        "    blk = []\n",
        "    for i in range(num_residuals):\n",
        "        if i == 0 and not first_block:\n",
        "            blk.append(Residual(input_channels, num_channels,\n",
        "                                use_1x1conv=True, strides=2))\n",
        "        else:\n",
        "            blk.append(Residual(num_channels, num_channels))\n",
        "    return blk"
      ],
      "metadata": {
        "id": "lsBxpAakFNur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))\n",
        "b3 = nn.Sequential(*resnet_block(64, 128, 2))\n",
        "b4 = nn.Sequential(*resnet_block(128, 256, 2))\n",
        "b5 = nn.Sequential(*resnet_block(256, 512, 2))"
      ],
      "metadata": {
        "id": "9YNXq2PRFSlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(b1, b2, b3, b4, b5,\n",
        "                    nn.AdaptiveAvgPool2d((1,1)),\n",
        "                    nn.Flatten(), nn.Linear(512, 10))"
      ],
      "metadata": {
        "id": "LZZ3aLeNFSdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(size=(1, 1, 224, 224))\n",
        "for layer in net:\n",
        "    X = layer(X)\n",
        "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
      ],
      "metadata": {
        "id": "mVtcA4atFVUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bldMzhPvXenk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr, num_epochs, batch_size = 0.01, 13, 256\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
        "\n",
        "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
      ],
      "metadata": {
        "id": "0UMkWYSAFVO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 图像增强"
      ],
      "metadata": {
        "id": "uKBzdkJ6hva4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install d2l==0.17.6"
      ],
      "metadata": {
        "id": "K_QzKeAGiHh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "a1LmbKubh2E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d2l.set_figsize()\n",
        "img = d2l.Image.open('./cat.png')\n",
        "d2l.plt.imshow(img)"
      ],
      "metadata": {
        "id": "cHhsBDm5h2Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply(img, aug, num_rows=2, num_cols=4, scale=1.5):\n",
        "    Y = [aug(img) for _ in range(num_rows * num_cols)]\n",
        "    d2l.show_images(Y, num_rows, num_cols, scale=scale)"
      ],
      "metadata": {
        "id": "x3uQojHmh2AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apply(img, torchvision.transforms.RandomHorizontalFlip())"
      ],
      "metadata": {
        "id": "lBcTi3yRh19o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apply(img, torchvision.transforms.RandomVerticalFlip())"
      ],
      "metadata": {
        "id": "YylnAVhNh164"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shape_aug = torchvision.transforms.RandomResizedCrop(\n",
        "    (200, 200), scale=(0.1, 1), ratio=(0.5, 2))\n",
        "apply(img, shape_aug)"
      ],
      "metadata": {
        "id": "Ej0Y4jknh14X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apply(img, torchvision.transforms.ColorJitter(\n",
        "    brightness=0.5, contrast=0, saturation=0, hue=0))"
      ],
      "metadata": {
        "id": "pRKCfUDTh1vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apply(img, torchvision.transforms.ColorJitter(\n",
        "    brightness=0, contrast=0, saturation=0, hue=0.5))"
      ],
      "metadata": {
        "id": "7wKhXgJ5iXFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_aug = torchvision.transforms.ColorJitter(\n",
        "    brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)\n",
        "apply(img, color_aug)"
      ],
      "metadata": {
        "id": "QsFGpllUiZMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augs = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomHorizontalFlip(), color_aug, shape_aug])\n",
        "apply(img, augs)"
      ],
      "metadata": {
        "id": "lYVuW6LHiZFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_images = torchvision.datasets.CIFAR10(train=True, root=\"../data\",\n",
        "                                          download=True)\n",
        "d2l.show_images([all_images[i][0] for i in range(32)], 4, 8, scale=0.8);"
      ],
      "metadata": {
        "id": "sU0LWu7Gicje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_augs = torchvision.transforms.Compose([\n",
        "     torchvision.transforms.RandomHorizontalFlip(),\n",
        "     torchvision.transforms.ToTensor()])\n",
        "\n",
        "test_augs = torchvision.transforms.Compose([\n",
        "     torchvision.transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "pmAnpvwiiceG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cifar10(is_train, augs, batch_size):\n",
        "    dataset = torchvision.datasets.CIFAR10(root=\"../data\", train=is_train,\n",
        "                                           transform=augs, download=True)\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                    shuffle=is_train, num_workers=d2l.get_dataloader_workers())\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "FfEGaTnJifHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 多gpu训练"
      ],
      "metadata": {
        "id": "IFBFwdQVijp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_batch_ch13(net, X, y, loss, trainer, devices):\n",
        "    \"\"\"用多GPU进行小批量训练\"\"\"\n",
        "    if isinstance(X, list):\n",
        "        # 微调BERT中所需\n",
        "        X = [x.to(devices[0]) for x in X]\n",
        "    else:\n",
        "        X = X.to(devices[0])\n",
        "    y = y.to(devices[0])\n",
        "    net.train()\n",
        "    trainer.zero_grad()\n",
        "    pred = net(X)\n",
        "    l = loss(pred, y)\n",
        "    l.sum().backward()\n",
        "    trainer.step()\n",
        "    train_loss_sum = l.sum()\n",
        "    train_acc_sum = d2l.accuracy(pred, y)\n",
        "    return train_loss_sum, train_acc_sum\n",
        "\n",
        "def train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,\n",
        "               devices=d2l.try_all_gpus()):\n",
        "    \"\"\"用多GPU进行模型训练\"\"\"\n",
        "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
        "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1],\n",
        "                            legend=['train loss', 'train acc', 'test acc'])\n",
        "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
        "    for epoch in range(num_epochs):\n",
        "        # 4个维度：储存训练损失，训练准确度，实例数，特点数\n",
        "        metric = d2l.Accumulator(4)\n",
        "        for i, (features, labels) in enumerate(train_iter):\n",
        "            timer.start()\n",
        "            l, acc = train_batch_ch13(\n",
        "                net, features, labels, loss, trainer, devices)\n",
        "            metric.add(l, acc, labels.shape[0], labels.numel())\n",
        "            timer.stop()\n",
        "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
        "                animator.add(epoch + (i + 1) / num_batches,\n",
        "                             (metric[0] / metric[2], metric[1] / metric[3],\n",
        "                              None))\n",
        "        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)\n",
        "        animator.add(epoch + 1, (None, None, test_acc))\n",
        "    print(f'loss {metric[0] / metric[2]:.3f}, train acc '\n",
        "          f'{metric[1] / metric[3]:.3f}, test acc {test_acc:.3f}')\n",
        "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec on '\n",
        "          f'{str(devices)}')"
      ],
      "metadata": {
        "id": "84dnSYPZifBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size, devices, net = 256, d2l.try_all_gpus(), d2l.resnet18(10, 3)\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) in [nn.Linear, nn.Conv2d]:\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "net.apply(init_weights)\n",
        "\n",
        "def train_with_data_aug(train_augs, test_augs, net, lr=0.001):\n",
        "    train_iter = load_cifar10(True, train_augs, batch_size)\n",
        "    test_iter = load_cifar10(False, test_augs, batch_size)\n",
        "    loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    train_ch13(net, train_iter, test_iter, loss, trainer, 10, devices)"
      ],
      "metadata": {
        "id": "GhH5Fb0hipmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_with_data_aug(train_augs, test_augs, net)"
      ],
      "metadata": {
        "id": "pEJmSEJAisio"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}